<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />

  <link rel="stylesheet" href="style.css" />
  <title>Computer Vision Final Project</title>

</head>


<body>
  <header>
    <h1><a href=".">CSE 455 Final Project</a></h1>

    <p>
      <strong>Team Members</strong>: Youssef Ben Taleb, Amanda Yuan
    </p>
  </header>
  <br>
  <h3>Problem:</h3>
  <br>
  <div>
  We humans can get confused by what we see quite easily, whether that's due to optical illusions
  or just two images being really similar. In our project, we experiment this phenomenon using
  Computer Vision techniques in order to investigate how computers can react to these slight differences. To do so we attempt to perform a binary classification between chihuahuas and muffins, two categories of images which can, at times, look exceedingly alike.
  </div>
    <br>
    <div>
        The following meme shows the confusion we try to create in our Computer Vision model:
    </div>
    <br>
    <img src="muffin-meme2.jpg">
    <br>
    <br>

    <h3>Data:</h3>

    <div>
        We chose the following <a href="https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification">Kaggle Dataset</a>.
        This dataset includes 6,000 scraped images from Google Images without duplicates.
        
    </div>
    <br>
    Here are some sample pictures from our dataset:
    <br>
    <img src="download.png">
    <br>

    <h3>Processing:</h3>
    <div> We took a number of steps to ensure uniformity of our data for training. We first
        filtered images by their aspect ratio such that we only have square images with a 1:1 ratio. This
        left us with about 500 images of muffins and 500 images of chihuahuas which fit this ratio.
        To ensure that both our training and test sets had a good balance of each type of image we
        allocated roughly 400 images of each kind to our training set and the rest to the test set.
        Since our GPUs have limited memory, we decided to scale down the images to a jpeg format with a
        dimensions of 64 x 64 x 3. We also flipped images on their horizontal axis 50% of the time
        in our training dataset to ensure more randomness to try and further confuse our model.
        Additionally, we used a batch size of 128 to load the data for every training iteration.

    </div>
    <br>
    <div>Our Data Processing is initially done on <a href="https://www.kaggle.com/code/youssefben03/cv-final-project-amanda-youssef">this Kaggle Notebook</a></div>
    <br>
    <h3>Algorithm:</h3>
    <div>
        We use a binary classification approach using a CNN model. We first start by using resnet18
        as it works very well for these types of classifications as we have seen in the class tutorials.
        The model is trained for 70 epochs with a learning rate of 0.01. We evaluate our model on the
        test data set we have. We are able to achieve 81.5% accuracy rate on the test set.
    
    </div>
    <br>
    Here is our Prediction Confusion Matrix:
    <br>
    <br>
    <img src="download (1).png">
    <br>
    <br>
    Model Loss:
    <br>
    <img src="download (2).png">

    <div>Our Model Code can be found on this <a href="https://colab.research.google.com/drive/1RVSDQ0adkiJ2MBcKPzMd2SVdDR4BKGyW?usp=sharing">Colab Notebook</a>.</div>
    <br>
    <h3>Work:</h3>
    <br>
    <div>
        <li>We initally started by understanding our <a href="https://www.kaggle.com/datasets/samuelcortinhas/muffin-vs-chihuahua-image-classification">Dataset</a> image types and scaling.</li>
        <li>We wrote this <a href="https://www.kaggle.com/code/youssefben03/cv-final-project-amanda-youssef">Kaggle Notebook</a> to process our data. We first start by filtering images by their 
            aspect ratio and keep ones with a 1:1 ratio. And then compress these images into a zip file to later process on our Google Colab Notebook.</li>
        <li>Our filtered and processed data is now used on this <a href="https://colab.research.google.com/drive/1RVSDQ0adkiJ2MBcKPzMd2SVdDR4BKGyW?usp=sharing#scrollTo=vTTCyaHrqt1U">Google Colab Notebook</a> 
            which is inspired by the Learning Transfer tutorial given in class (<a href="https://colab.research.google.com/drive/1EBz4feoaUvz-o_yeMI27LEQBkvrXNc_4?usp=sharing">this Notebook</a>). We split the data
            into a training set (batch of size 128) and a test set and evaluate our model after 70 iterations of training on top of the Resnet18 model.
        </li>

    </div>

    <br>
    <h3>Result:</h3>
    <br>
    <div>
        Our model ended up achieving higher accuracies and lower losses than we expected. We could see
        that in our confusion matrix that our chihuahuas were very well predicted. However, muffins
        do get confused with chihuahuas very often at a 33% rate. Here is an example of a muffing
        image which was confused with a chihuahua by our model:
    </div>
    <br>
    <img src="download (3).png">
    <br>
    <div>
        Our model reaches a high accuracy for images that could be mixed up by even humans.
        We personally found a lot of similarities between the muffin and chihuahua images
        but could eventually figure out which was which after focusing on the images for some time.
        However, CV models don't work like that and generally look for similar patters in images
        which can confuse the models.
    </div>
    <br>
    <div>
        Overall, this project provided us with a response to our inquiry and let us take initiative
        to further explore Computer Vision models and different ways to improve and use them for our
        own benefit and amusement.
    </div>
    <br>
    <footer>
        <p>
        CSE 455: Final Project
        <br>
        Winter 2023
    </p>
    </footer>
</body>

</html>

